---
title: Trl
---

# TRL - Transformer Reinforcement Learning

## åŠŸèƒ½

TRL æ˜¯ä¸€ä¸ªç”¨äºä½¿ç”¨å¼ºåŒ–å­¦ä¹ åè®­ç»ƒåŸºç¡€æ¨¡å‹çš„å…¨é¢åº“ã€‚æ”¯æŒå…ˆè¿›æŠ€æœ¯å¦‚ç›‘ç£å¾®è°ƒ (SFT)ã€è¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (PPO) å’Œç›´æ¥åå¥½ä¼˜åŒ– (DPO)ã€‚åŸºäº ğŸ¤— Transformers ç”Ÿæ€ï¼Œæ”¯æŒå„ç§æ¨¡å‹æ¶æ„å’Œæ¨¡æ€ï¼Œå¯æ‰©å±•åˆ°å„ç§ç¡¬ä»¶è®¾ç½®ã€‚

### äº®ç‚¹

- **Trainers**: æä¾›å¦‚ `SFTTrainer`ã€`GRPOTrainer`ã€`DPOTrainer`ã€`RewardTrainer` ç­‰è®­ç»ƒå™¨ã€‚
- **é«˜æ•ˆå¯æ‰©å±•**: åˆ©ç”¨ ğŸ¤— Accelerate è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ”¯æŒ PEFT è¿›è¡Œé‡åŒ–/LoRA/QLoRAï¼Œé›†æˆ Unsloth åŠ é€Ÿè®­ç»ƒã€‚
- **å‘½ä»¤è¡Œç•Œé¢ (CLI)**: æ— éœ€ç¼–å†™ä»£ç å³å¯å¾®è°ƒæ¨¡å‹ã€‚

## ç”¨æ³•

### å®‰è£…

```bash
pip install trl
```

æˆ–ä»æºç å®‰è£…ï¼š

```bash
pip install git+https://github.com/huggingface/trl.git
```

### å¿«é€Ÿå¼€å§‹

#### SFTTrainer ç¤ºä¾‹

```python
from trl import SFTTrainer
from datasets import load_dataset

dataset = load_dataset("trl-lib/Capybara", split="train")

trainer = SFTTrainer(
    model="Qwen/Qwen2.5-0.5B",
    train_dataset=dataset,
)
trainer.train()
```

#### GRPOTrainer ç¤ºä¾‹

```python
from datasets import load_dataset
from trl import GRPOTrainer

dataset = load_dataset("trl-lib/tldr", split="train")

def reward_num_unique_chars(completions, **kwargs):
    return [len(set(c)) for c in completions]

trainer = GRPOTrainer(
    model="Qwen/Qwen2-0.5B-Instruct",
    reward_funcs=reward_num_unique_chars,
    train_dataset=dataset,
)
trainer.train()
```

#### DPOTrainer ç¤ºä¾‹

```python
from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import DPOConfig, DPOTrainer

model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
dataset = load_dataset("trl-lib/ultrafeedback_binarized", split="train")
training_args = DPOConfig(output_dir="Qwen2.5-0.5B-DPO")
trainer = DPOTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    processing_class=tokenizer
)
trainer.train()
```

### CLI ç”¨æ³•

**SFT:**

```bash
trl sft --model_name_or_path Qwen/Qwen2.5-0.5B \
    --dataset_name trl-lib/Capybara \
    --output_dir Qwen2.5-0.5B-SFT
```

**DPO:**

```bash
trl dpo --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --dataset_name argilla/Capybara-Preferences \
    --output_dir Qwen2.5-0.5B-DPO
```

æ›´å¤šè¯¦æƒ…è¯·å‚è€ƒ [å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/trl/index)ã€‚
