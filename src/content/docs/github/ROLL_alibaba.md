---
title: repository
---

# ROLL: 大规模强化学习优化库

ROLL 是一个高效且用户友好的强化学习库，专为利用大规模 GPU 资源的大语言模型（LLMs）设计。它在人类偏好对齐、复杂推理和多轮智能体交互场景等关键领域显著提升 LLM 性能。

## 核心功能

### 多任务强化学习训练（RLVR）

- 涵盖数学、编程、通用推理、开放式问答、指令遵循等多个领域
- 灵活的 `domain_batch_size` 分布控制
- 样本级异步并行 Rollout、异步奖励计算和动态采样
- 支持异步训练（正在实现中）

### 智能体强化学习

- 多轮交互能力，适用于游戏、多轮对话、工具使用等场景
- 环境级异步并行 rollout
- 支持异步训练
- 多轮交互 rollout 支持本地调试，提高多轮交互业务开发效率
- 支持 TrajectoryWise（StartPO）和 StepWise（GiGPO）训练范式

### 算法友好

- 默认提供灵活且丰富的强化学习策略配置
- 超过 20 种丰富的强化学习策略选项，如奖励归一化、奖励裁剪、各种优势估计方法等
- 开箱即用的强化学习算法支持，如 **PPO、GRPO、Reinforce++、TOPR、RAFT++、GSPO** 等

### 丰富的训练和推理引擎

- 基于 Ray 的多角色分布式架构
- 策略抽象统一各种后端，轻松实现从单机到千卡 GPU 集群的操作
- 推理/生成支持 vLLM、SGLang
- 训练支持 DeepSpeed（ZeRO）、Megatron-LM 5D 并行（mcore-adapter、dp/tp/pp/cp/ep）、FSDP（正在实现中）
- 极致的卸载/重载能力
- 支持 LoRA 训练
- 支持 FP8 rollout（LLM 作为评判者的 FP8 推理，BF16 训练的 FP8 rollout 正在开发中）

### 其他特性

- **AutoDeviceMapping**：支持为不同角色自定义设备映射，灵活管理共置和分离部署
- **可观测性**：集成 SwanLab / WandB / TensorBoard，跟踪每个领域和奖励类型的性能
- **丰富的后训练技术支持**：
  - 智能体强化学习 LLM & VLM
  - RLVR LLM & VLM
  - 蒸馏流水线 LLM & VLM
  - DPO 流水线
  - SFT 流水线（正在开发中）

## 支持的模型

ROLL 支持多种主流大语言模型：

- Qwen3（8B/14B/32B）
- Qwen3-MoE（30A3/235A22）
- Qwen2.5（7B/14B/32B/72B）
- Qwen2.5 VL 模型
- 其他兼容模型

## 安装和使用

### 快速开始

1. 安装依赖：根据需求选择相应的 requirements 文件
2. 配置环境：支持单节点和多节点部署
3. 运行训练：使用提供的配置文件进行 RLVR 或智能体强化学习训练

### 配置系统

- 灵活的 YAML 配置文件
- 支持自定义设备映射
- 丰富的算法参数配置

## 应用场景

### 学术研究

- 强化学习算法研究
- 大语言模型对齐研究
- 智能体行为研究

### 工业应用

- 电商搜索相关性优化
- 推荐系统优化
- 广告竞价策略优化
- 实时推理系统

## 技术架构

ROLL 采用多角色分布式架构：

- **Actor**：负责模型推理和生成
- **Learner**：负责模型训练
- **Environment**：负责环境交互和奖励计算
- **Rollout**：负责数据收集

通过 Ray 实现灵活的资源分配和异构任务调度，集成 Megatron-Core、SGLang 和 vLLM 等前沿技术来加速模型训练和推理。

## 社区和支持

- 开源协议：Apache-2.0
- 活跃的开发团队和社区支持
- 详细的文档和示例代码
- 持续的功能更新和性能优化

ROLL 为大语言模型的强化学习训练提供了一个完整、高效且易用的解决方案，是研究和应用强化学习于大语言模型的理想选择。
