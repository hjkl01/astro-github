---
title: crawlab
---

# Crawlab 项目描述

## 项目地址
[https://github.com/crawlab-team/crawlab](https://github.com/crawlab-team/crawlab)

## 主要特性
Crawlab 是一个开源的分布式爬虫管理系统，支持多种编程语言的爬虫框架，如 Scrapy、PySpider 和 Colly 等。它提供了一个 Web 界面来管理和监控爬虫任务，具有以下核心特性：
- **分布式架构**：支持多节点部署，实现爬虫任务的水平扩展和负载均衡。
- **多语言支持**：兼容 Python、Node.js、PHP 等多种语言开发的爬虫项目。
- **任务调度**：内置调度器，支持定时任务、并发控制和任务优先级设置。
- **监控与日志**：实时监控爬虫运行状态，提供详细的日志查看和性能指标（如速度、成功率）。
- **插件系统**：可扩展插件，支持自定义爬虫模板和结果处理。
- **数据存储**：集成 MongoDB 等数据库，用于存储爬取结果和元数据。
- **用户管理**：支持多用户角色和权限控制，便于团队协作。

## 主要功能
- **爬虫管理**：通过 Web 界面上传、编辑和部署爬虫项目，支持版本控制。
- **任务执行**：一键启动、停止或重启任务，支持批量操作和环境变量配置。
- **结果处理**：自动解析和导出爬取数据，支持 JSON、CSV 等格式输出。
- **节点管理**：监控分布式节点的状态、健康检查和资源使用情况。
- **仪表盘**：可视化界面显示任务统计、错误分析和历史记录。
- **API 接口**：提供 RESTful API，便于集成到其他系统中。

## 用法
1. **安装**：
   - 使用 Docker 快速部署：克隆仓库后运行 `docker-compose up -d`。
   - 或通过 pip 安装 Python 版本：`pip install crawlab`。
   - 详细安装指南见仓库的 [INSTALL.md](https://github.com/crawlab-team/crawlab/blob/master/INSTALL.md)。

2. **配置**：
   - 启动后访问 `http://localhost:8080`，默认用户名/密码为 `admin/admin`。
   - 在设置中配置 MongoDB 连接和节点信息。

3. **使用步骤**：
   - **创建项目**：在 Web 界面上传爬虫代码（如 Scrapy 项目文件夹）。
   - **添加任务**：设置任务参数（如 URL、定时规则），启动执行。
   - **监控任务**：查看实时日志、结果数据和统计图表。
   - **扩展节点**：在多机环境中安装 Crawlab 服务端，注册为从节点以实现分布式运行。
   - **导出数据**：任务完成后，从结果页面下载或通过 API 获取数据。

更多细节请参考仓库文档。