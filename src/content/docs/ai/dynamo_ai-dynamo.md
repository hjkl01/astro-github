---
title: Dynamo
---

# Dynamo (ai-dynamo)

## é¡¹ç›®ç®€ä»‹

NVIDIA Dynamo æ˜¯ä¸€ä¸ªé«˜ååé‡ã€ä½å»¶è¿Ÿçš„æ¨ç†æ¡†æ¶ï¼Œä¸“ä¸ºåœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼ç¯å¢ƒä¸­æœåŠ¡ç”Ÿæˆå¼AIå’Œæ¨ç†æ¨¡å‹è€Œè®¾è®¡ã€‚å®ƒæ”¯æŒå¤šGPUã€å¤šèŠ‚ç‚¹æ¶æ„ï¼Œèƒ½å¤Ÿåè°ƒå¤šä¸ªGPUå’ŒæœåŠ¡å™¨ï¼Œå®ç°é«˜æ•ˆçš„æ¨ç†æœåŠ¡ã€‚

## ä¸»è¦åŠŸèƒ½

- **æ¨ç†å¼•æ“æ— å…³**ï¼šæ”¯æŒ TRT-LLMã€vLLMã€SGLang ç­‰å¤šç§æ¨ç†å¼•æ“
- **Disaggregated Prefill & Decode Inference**ï¼šåˆ†ç¦»é¢„å¡«å……å’Œè§£ç é˜¶æ®µï¼Œæœ€å¤§åŒ–GPUååé‡ï¼Œæ”¯æŒååé‡å’Œå»¶è¿Ÿçš„æƒè¡¡
- **åŠ¨æ€GPUè°ƒåº¦**ï¼šæ ¹æ®éœ€æ±‚æ³¢åŠ¨ä¼˜åŒ–æ€§èƒ½
- **LLM-awareè¯·æ±‚è·¯ç”±**ï¼šé¿å…ä¸å¿…è¦çš„KVç¼“å­˜é‡æ–°è®¡ç®—
- **åŠ é€Ÿæ•°æ®ä¼ è¾“**ï¼šä½¿ç”¨NIXLå‡å°‘æ¨ç†å“åº”æ—¶é—´
- **KVç¼“å­˜å¸è½½**ï¼šåˆ©ç”¨å¤šä¸ªå†…å­˜å±‚æ¬¡æé«˜ç³»ç»Ÿååé‡

## æ”¯æŒçŸ©é˜µ

| åŠŸèƒ½                       | vLLM | SGLang | TensorRT-LLM |
| -------------------------- | ---- | ------ | ------------ |
| Disaggregated Serving      | âœ…   | âœ…     | âœ…           |
| Conditional Disaggregation | ğŸš§   | ğŸš§     | ğŸš§           |
| KV-Aware Routing           | âœ…   | âœ…     | âœ…           |
| Load Based Planner         | ğŸš§   | ğŸš§     | ğŸš§           |
| SLA-Based Planner          | âœ…   | âœ…     | âœ…           |
| KVBM                       | âœ…   | ğŸš§     | âœ…           |

## å®‰è£…å’Œä½¿ç”¨

### 1. åˆå§‹è®¾ç½®

æ¨èä½¿ç”¨ Ubuntu 24.04 å’Œ x86_64 CPUã€‚

å®‰è£… uv Python åŒ…ç®¡ç†å™¨ï¼š

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

å®‰è£… Python å¼€å‘å¤´æ–‡ä»¶ï¼š

```bash
sudo apt install python3-dev
```

å®‰è£… etcd å’Œ NATSï¼š

```bash
# ä½¿ç”¨ Docker Compose å¿«é€Ÿè®¾ç½®
docker compose -f deploy/docker-compose.yml up -d
```

### 2. é€‰æ‹©å¼•æ“

åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…å¯¹åº”å¼•æ“ï¼š

```bash
uv venv venv
source venv/bin/activate
uv pip install pip

# é€‰æ‹©ä¸€ä¸ªå¼•æ“
uv pip install "ai-dynamo[sglang]"  # æˆ– [vllm], [trtllm]
```

### 3. è¿è¡Œ Dynamo

å¯åŠ¨ OpenAI å…¼å®¹çš„ HTTP æœåŠ¡å™¨ï¼š

```bash
python -m dynamo.frontend --http-port 8000
```

å¯åŠ¨æ¨ç†å¼•æ“ï¼ˆä»¥ SGLang ä¸ºä¾‹ï¼‰ï¼š

```bash
python -m dynamo.sglang --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B
```

### å‘é€è¯·æ±‚

```bash
curl localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [{"role": "user", "content": "Hello, how are you?"}],
    "stream": false,
    "max_tokens": 300
  }'
```

## å¼•æ“æ”¯æŒ

### vLLM

```bash
uv pip install ai-dynamo[vllm]
python -m dynamo.vllm --help
```

### SGLang

```bash
apt install -y libnuma-dev
uv pip install ai-dynamo[sglang]
python -m dynamo.sglang --help
```

### TensorRT-LLM

æ¨èä½¿ç”¨ NGC PyTorch Containerï¼Œå®‰è£…ä¾èµ–åï¼š

```bash
uv pip install ai-dynamo[trtllm]
python -m dynamo.trtllm --help
```

## éƒ¨ç½²å’ŒåŸºå‡†æµ‹è¯•

- Kubernetes éƒ¨ç½²ï¼šå‚è€ƒ Quickstart Guide
- åŸºå‡†æµ‹è¯•ï¼šä½¿ç”¨ AIPerf æ¯”è¾ƒä¸åŒéƒ¨ç½²æ‹“æ‰‘çš„æ€§èƒ½
- SLA é©±åŠ¨éƒ¨ç½²ï¼šä¼˜åŒ–éƒ¨ç½²ä»¥æ»¡è¶³ SLA è¦æ±‚

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.nvidia.com/dynamo/latest/
